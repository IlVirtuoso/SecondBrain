{
	"nodes":[
		{"id":"374730ea6e8d5b3a","type":"text","text":"## Stochastic process \nA stochastic process is a collection of RVs $\\{X(t), t \\in T\\}$ all defined on a sample space defined by elements in the index set T.\n3 elements must be specified:\n- The process state space \n- the index parameter \n- dependencies among RVs in $\\{X(t),t \\in T\\}$ ","x":-240,"y":360,"width":580,"height":280,"color":"2"},
		{"id":"f78ebbec42cdd6e7","type":"text","text":"## Index \nIf the index set T is finite we have a discrete time stochastic process (at the end of the day ecc..). Otherwise the process is called continuous time. \n\nfor discrete we denote it as $\\{X_n,n \\geq 0\\}$ \nfor continuous we denote it as $\\{X(t),t \\geq 0\\}$  ","x":-240,"y":920,"width":580,"height":260,"color":"2"},
		{"id":"fb96abbeb54ad571","type":"text","text":"## Basic probability theory \n - A discrete RV X is completely characterized by it's PDF $F_x(x)=P[X=x]$  or probability that RV X is equal to x \n - A continuos RV X is completely characterized by it's CDF $F_x(x)=P[X \\leq x]$ , the pdf is often defined also as $f_x=\\frac{dF_x(x)}{dx}$ \n\nRecall that given 2 Events A,B the conditional probability $P[A|B] = \\frac{P[A,B]}{P[B]}$ , thus it follows \n$P[A,B]=P[A|B]*P[B]$  ","x":2000,"y":973,"width":680,"height":415,"color":"2"},
		{"id":"2ef3329918baefb0","type":"text","text":"## Statistical dependencies \nDenote all random variables as a vector $X=[X(t_1),X(t_2),...]$ , To fully characterize the joint probability distribution function (PDF) of the stochastic process:\n$F_x(x;t)=P[X(t_1) \\leq x_1, X(t_2) \\leq x_2,...,X(t_n) \\leq x_n]$  all $x=(x_1,x_2,...,x_n)$  and $t=(t_1,t_2,...,t_n)$ \nmust be specified, and this can be only done by imposing some restrictions.\n\nusing the definition of conditional probability $P[A,B]=P[A|B]*P[B]$ we can write the joint pdf as the product of 2 factors:\n$$\n\\begin{align}\nP[X(t_1) \\leq x_1,..., X(t_n) \\leq x_n,X(t_n+1) \\leq x_n+1]= \\\\ P[X(t_{n+1}) \\leq x_{n+1}| X(t_1) \\leq x_1,...,X(t_n) \\leq x_n]*P[X(t_1) \\leq x_1,...,X(t_n) \\leq x_n]\n\\end{align}\n$$ \n repeating the same reasoning we obtain \n$$\n\\begin{align}\nP[X(t_{n+1}) \\leq x_{n+1}| X(t_1) \\leq x_1,...,X(t_n) \\leq x_n]*\\\\\nP[X(t_{n}) \\leq x_{n}| X(t_1) \\leq x_1,...,X(t_{n-1}) \\leq x_{n-1}]*\\\\\nP[X(t_{n-1}) \\leq x_{n-1}| X(t_1) \\leq x_1,...,X(t_{n-2}) \\leq x_{n-2}]*\\\\...\\\\ \nP[X(t_1) \\leq x_1]\n\\end{align}\n$$","x":660,"y":920,"width":820,"height":520,"color":"1"},
		{"id":"817d4e0ae2d49396","type":"text","text":"## Class of stochastic processes \n- Stationary process: for any constant $\\tau$ is true $F_x(x;t+\\tau)=F_x(x;t)$  where $t+\\tau=(t_1+\\tau,t_2+\\tau,...,t_n+\\tau)$ \n- independent processes: if the joint PDF (in case of continuous space) factorize: $f_X(x;t)=f_{X1}(x_1;t_1) ... f_{Xn}(x_n;t_n)$ \n- Markov process: a discrete state stochastic process (a chain) is said to satisfy the markov property if $P[X(t_n+1) = x_n+1| X(t_n)=x_n,...,X(t_1)=x_1]=P[X(t_{n+1})=x_{n+1}| X(t_n)=x_n]$ ","x":660,"y":1640,"width":820,"height":360,"color":"3"},
		{"id":"d7e584c1e6e88686","type":"text","text":"## Graph representation \nA DTMC can be represented as a state transition diagram that is a weighted graph directed where:\n- The number of nodes is equal to the number of states \n- there is an arc from node i to node j if $p_{ij}>0$ \n- the weight of arc is equal to $p_{ij}$ \n![[Pasted image 20231202154042.png]]","x":-2460,"y":-400,"width":640,"height":420,"color":"3"},
		{"id":"c11a23cb46738c9d","type":"text","text":"## Matrix representation\na DTMC can be represented as a square transition probability matrix P where:\n- the dimension d is equal to the number of states \n- element in row i comlumn j is equal to $p_{ij}$ \n- all rows of P sum to 1\nthis matrix is said to be a stochastic matrix \n\n$$\nP = \\begin{pmatrix}\np_{11} && p_{12} &&...&&p_{1d}\\\\\np_{21} && P_{22} &&...&&p_{2d}\\\\\n...\\\\\np_{d1} && p_{d2} && ... && p_{dd}\n\\end{pmatrix}\n$$","x":-3440,"y":-400,"width":640,"height":360,"color":"3"},
		{"id":"935be3360b506abf","type":"text","text":"## State space \nThe state space of a stochastic process is the set of all possible values RV $X(t)$ can assume.\n\n- If the set is finite or countable we have a discrete state stochastic process (or chain)\n- Else is a continuos state stochastic process whose state space is represent by a subset of the set of real number","x":-1120,"y":930,"width":600,"height":300,"color":"2"},
		{"id":"c08e3d70444f37a8","type":"text","text":"## Markov chains purpose\n\nthe answer to those type of questions:\n- How long a gambler will play before ruins? \n- What is the probability that tomorrow will be sunny?\n\nThe markov chains are a set of models that evolute over time (sequential indexes). ","x":600,"y":360,"width":580,"height":280,"color":"5"},
		{"id":"205c68fa78ad62a8","type":"text","text":"## Definitions \n- A DTMC is irreducible if any state can be reached from any other state. Formally $\\forall i,j \\ \\exists m_0(i,j):p_{ij}^{(m_0(i,j))}>0$ \n- A subset C of the state space is said to be closed if no 1 step transition is possible between states in C and outside C. if |C|=1 that state is absorbing \n- if the state space is closed and doesn't contain any closed subset then DTMC is irreducible ","x":-4460,"y":-550,"width":640,"height":300,"color":"1"},
		{"id":"a917fa7a67d05f37","type":"text","text":"## Ergodicity\n- a state i is said to be ergodic if it is aperiodic and positive recurrent \n- if all state of a DTMC are ergodic, the chain is ergodic.\n ![[Pasted image 20231203114257.png]]","x":-6220,"y":-573,"width":620,"height":287,"color":"1"},
		{"id":"c2df5bf426c9e5da","type":"text","text":"## Return probabilities \nIn order to classify states of a DTMC define\n$f_j^{(n)}=$ P\\[return to state j occurs n step after leaving it]\n\nwe can then derive the probability to return to state j as $f_j=\\sum^{\\infty}_{n=1}f_j^{(n)}$ \n\n- if $f_j=1$ state j is recurrent\n- if $f_j<1$ state j is transient \n- If the step necessary to return to state j is $\\gamma,2 \\gamma, 3 \\gamma$ where $\\gamma$ is the largest integer satisfy this condition the state j is called period with period $\\gamma$\n- if $\\gamma = 1$ then state j is aperiodic\nThe average recurrence time is defined as $M_j=\\sum^{\\infty}_{n=1}nf_j^{(n)}$ \n- if $M_j=\\infty$ state j is called null recurrent \n- if $M_j<\\infty$ state j is called positive recurrent \n\n","x":-5460,"y":-640,"width":640,"height":420,"color":"1"},
		{"id":"b0b19e3eba04a1f4","type":"text","text":"## Solution\nSolve a DTMC means compute $\\pi_j^{(n)}=P[X_n=j]$  that is the probability the state of the DTMC at the nth step is equal to j. This is can be done knowing the initial $P[X_0=k]$\n\nIn a time-homogeneous, irreducible and aperiodic DTMC the limit probabilities $\\pi_j=\\lim_{n \\rightarrow \\infty} \\pi_j^{(n)}$ always exists and are idependent of the initial state. Also:\n- if all states are transient or null recurrent --> $\\pi_j=0$ for all state and a steady state solution do not exists \n- else if all are positive recurrent --> $\\pi_j>0$ for all states and $\\{\\pi_j\\}$ is the steady state solution with $\\pi_j=\\frac{1}{M_j}$ ","x":-5480,"y":-100,"width":680,"height":340,"color":"1"},
		{"id":"4a5d3e9159bb48f4","type":"text","text":"## Transient state distribution \nlet $\\pi^{(n)} = [\\pi^{(n)}_0,\\pi^{(n)}_1,\\pi^{(n)}_2,...]$ be the probability vector of the state of the DTMC at the nth step (each element represent the probability to be in that state at time n). \n\nthus $\\forall i, \\pi_i^1=\\pi_0^0p_{0i}+\\pi_1^0p_{1i}+\\pi_2^0p_{2i}+...$  in matrix form $\\pi^{(1)}=\\pi^{(0)}P$ (i.e. the distribution at the 1 pass is equal to summing probability at pass 0 with the product of the transition probabilities).\n\nand so $\\pi^{(2)}=\\pi^{(1)}P=\\pi^{(0)}P^2$ . Thus we can say $\\pi^{(n)}=\\pi^{(0)}P^n$  (this is the power matrix method).\nAlso $\\pi^{(n)}=\\pi^{(n-1)}P$ (we can compute the distribution at n just knowing the vector at the precedent pass i.e vector multiplication method). \n\n","x":-6380,"y":-80,"width":740,"height":300,"color":"1"},
		{"id":"10546463f6f462dd","type":"text","text":"## Time homogeneous DTMC \nin a time-homogeneous DTMC transition probabilities are stationary, the probability to be in a certain state after m steps depends only on m.\n$p_{ij}^{(m)}=P[X_{n+m}=j|X_n=i]$ is the m-step transition probabilities. \nFor the markov property $p_{ij}^{(m)}=\\sum_{k}p_{ik}^{(m-1)}p_{kj}$ .","x":-4460,"y":-40,"width":640,"height":220,"color":"1"},
		{"id":"8411d47feb4ccd4a","type":"text","text":"## Sojourn time\nthe units of time spent without interruptions in each state is distributed according to a geometric distribution. Assume state j is just entered: \n- The probability next state is still j is equal to $p_{jj}$ \n- dual for not being in j $1-p_{jj}$ \n\nthanks to the markov property (memoryless) the probability next state is still j doesn't depend on how many times we hit j. So the probability the state in j after m steps is \n$(1-p_{jj})p_{jj}^m$ \n\nthe Geometric distribution is the only memoryless discrete distribution ","x":-5500,"y":360,"width":680,"height":360,"color":"1"},
		{"id":"84e33f30ca11a5c0","type":"text","text":"## Chapman kolmogorov equation \nusing the definition of conditional probability and conditioning both sides of A $P[B,C|A]=P[B|A]*P[C|A,B]$ \n\n- let A-->$X_m=i$ , B-->$X_q=k$ , C-->$X_n=j$ => $p_{ij}(m,n)=\\sum_kPr\\{X_q=k|X_m=i\\}Pr\\{X_n=j|X_q=k,X_m=i\\}$ \n\nThen from markov property we derive the chapman kolmogrov equation \n$$\np_{ij}(m,n)=\\sum_kp_{ik}(m,q)p_{kj}(q,n)\n$$\n \n(i.e the probability of transition is the sum of all probabilities of transition from state i to k and to k to j). For time homogeneous DTMC it simplifies to $p_{ij}^{(n-m)}=\\sum_kp_{ik}^{(q-m)}p_{kj}^{(n-q)}$  ","x":-5500,"y":1300,"width":720,"height":400,"color":"1"},
		{"id":"033bd95d29fb1bd8","type":"text","text":"## Discrete time markov chains\nstochastic processes: discrete state space (chain), discrete time (index set is finite), satisfy markov property\n\nfor DTMC $\\{X_n\\}$ we write the markov property as $P[X_n=j|X_1=x_1,...,X_{n-1}=x_{n-1}]=P[X_n=j|X_{n-1}=x_{n-1}]$ \nif we know the initial probability distribution $P[X_0=k]$ we can obtain any state at time n.\n\nThe probability at the right hand side in the previous equation is called transition probability $p_{ij}(n)=P[X_n=j|X_{n-1}=i]$ , if transition probability are independent of n we have a time homogeneous DTMC where we denote $p_{ij}=P[X_n=j|X_{n-1}=i]$ the transition probabilities. Furthermore $\\forall i , \\sum_j p_{ij}=1$ ","x":-2880,"y":290,"width":640,"height":420,"color":"1"},
		{"id":"178bdf8a6493081f","type":"text","text":"## Death birth process ","x":-4460,"y":1960,"width":640,"height":420,"color":"1"},
		{"id":"48baf6027cb9b1fb","type":"text","text":"## Non homogeneous DTMC\nlet $p_{ij}(m,n)= Pr\\{X_n=j|X_m=i\\}$ that is the probability the chain is in state j at time n given that it was in sate i at time m $n \\geq m$ . \nTransition from state i to state j must occur through some intermediate state k at time q (i-->k-->j). \n\nprobability can be espressed as  $p_{ij}(m,n) =\\sum_k Pr\\{X_n=j,X_q=k|X_m=i\\}$.","x":-4460,"y":1380,"width":640,"height":240,"color":"1"},
		{"id":"8a37bedbd282f0df","type":"text","text":"## Transition probabilities\nmatrix P is actually a function of time n $P(n)=[p_{ij}(n,n+1)]$ . So after k steps transition probabilities is not the kth power of P.\n\nlet $H(m,n)=[p_{ij}(m,n)]$ , hence $H(n,n+1)=P(n)$.\n\nin matrix form Chapman-Kolmogrov equations reads as  $H(m,n)=H(m,q)H(q,n)$ with the additional condition $H(n,n)=I$ , known also as forward chapman kolmogorov\n\nbackward is just $H(m,n)=P(m)H(m+1,n)$ both describe the same phenomenon.\n\nSimilarly is possible to show that $\\pi^{(n+1)}=\\pi^{(n)}P(n)$  whose solution is $\\pi^{(n+1)}=\\pi^{(0)}H(0,n+1)$ \n \nand also in the time homogeneous case  $\\pi^{(n+1)}=\\pi^{(0)}P^{n+1}$\n","x":-6440,"y":1310,"width":720,"height":380,"color":"1"},
		{"id":"8ab38c1422963ca9","type":"text","text":"## Using the Z transform \nit is possible to use to Z transform of $\\pi^{(n)}=\\pi^{(n-1)}P$ in order to obtain $P^n=C+(n+1)(-\\frac{1}{4})^n D_1+(-\\frac{1}{4})^nD_2$ and have a more simple computation respect to the power matrix method in order to compute steady state solutions. \n\nlet $\\Pi(z)= \\sum^{\\infty}_{n=0}\\pi^{(n)}z^n$ where z is a complex variable such that $|z| \\leq 1$ and after some algebra \n$\\Pi(z)= \\pi^{(0)}[I-zP]^{-1}$ . Using anti transformation we obtain $\\pi^{(n)}=\\frac{1}{n!}\\frac{d^n \\Pi(z)}{dz^n}$ matrix inversion for $[I-zP]^{-1}$ \nwill lead to the solution.","x":-8520,"y":-75,"width":820,"height":290,"color":"4"},
		{"id":"26cc4c01193cef45","type":"text","text":"## Global balance equation \nmatrix equation for the limit solution of state probabilities is $\\pi=\\pi P$ and the jth component is $\\pi_j=\\sum_i \\pi_ip_{ij}$ that can be also written as \n$$\n(1-p_{jj})\\pi_j=\\sum_{i \\neq j}\\pi_i p_{ij}\n$$\nLeft hand side:\n$P_{jj}$ is the probability that the probability mass $\\pi_j$ does not flow out state j. And so the dual for $(1-p_{jj})$ . Thus $(1-p_{jj})\\pi_j$ is the fraction of probability mass flowing out of state j. \n\nRight hand side\nfor any other state i where $i \\neq j$ quantity $\\pi_ip_{ij}$ is the probability mass flowing out state i and entering state j. It follows that $\\sum_{i \\neq j} \\pi_i p_{ij}$ is the total probability mass flowing into state j. ","x":-7560,"y":1255,"width":960,"height":490,"color":"1"},
		{"id":"a8ab951f3c5c0e8f","type":"text","text":"## limit state distribution \nin this kind of chains the limit probabilities $\\pi_j=\\lim_{n \\rightarrow \\infty}\\pi_j^{(n)}$  (i.e the steady state solution) always exists and are independent of the initial state.\nBy definition we have $\\pi=[\\pi_0,\\pi_1,\\pi_2,...] = \\lim_{n \\rightarrow \\infty}\\pi^{(n)}$ \n- if we start from $\\pi^{(n)}=\\pi^{(0)}P^n$ --> $\\lim_{n \\rightarrow \\infty} \\pi^{(n)} = \\lim_{n \\rightarrow \\infty}\\pi^{(0)}P^n$ , thus $\\pi = \\pi^{(0)}P^{\\infty}$. \n- else from $\\pi^{(n)}=\\pi^{(n-1)}P$ --> $\\lim_{n \\rightarrow \\infty}\\pi^{(n)}=\\lim_{\\rightarrow \\infty}\\pi^{(n-1)}P$.\n \nin all case we obtain $\\pi = \\pi P$ , this matrix equation represent the system of linearly dependent\nequations $\\pi_j=\\sum_i \\pi_i p_{ij}$ with the normalizing condition $\\sum_i \\pi_i = 1$ we obtain a unique solution. \n\nThe rows of $P^\\infty$ are all equal to the limit distribution $\\pi$ , since $\\pi=\\pi^{(0)} P^\\infty$ for any value of $\\pi^{(0)}$ \n$$\nP^\\infty=\n\\begin{bmatrix}\n\\pi_0 && \\pi_1 && \\pi_2 && ... \\\\\n\\pi_0 && \\pi_1 && \\pi_2 && ... \\\\\n\\pi_0 && \\pi_1 && \\pi_2 && ... \\\\\n...\n\\end{bmatrix}\n$$","x":-7450,"y":-160,"width":740,"height":460,"color":"1"}
	],
	"edges":[
		{"id":"63ccaf7ed731f5a6","fromNode":"374730ea6e8d5b3a","fromSide":"bottom","toNode":"935be3360b506abf","toSide":"top"},
		{"id":"8c283489a1eef7af","fromNode":"374730ea6e8d5b3a","fromSide":"bottom","toNode":"f78ebbec42cdd6e7","toSide":"top"},
		{"id":"229d069b07ab5a80","fromNode":"374730ea6e8d5b3a","fromSide":"bottom","toNode":"2ef3329918baefb0","toSide":"top"},
		{"id":"bfd48a56be1edf18","fromNode":"fb96abbeb54ad571","fromSide":"left","toNode":"2ef3329918baefb0","toSide":"right"},
		{"id":"3ce30ea32d82415f","fromNode":"2ef3329918baefb0","fromSide":"bottom","toNode":"817d4e0ae2d49396","toSide":"top"},
		{"id":"902d90456b2310d5","fromNode":"374730ea6e8d5b3a","fromSide":"left","toNode":"033bd95d29fb1bd8","toSide":"right"},
		{"id":"7bdded040207fe68","fromNode":"033bd95d29fb1bd8","fromSide":"top","toNode":"c11a23cb46738c9d","toSide":"bottom"},
		{"id":"36517c15f136499e","fromNode":"033bd95d29fb1bd8","fromSide":"top","toNode":"d7e584c1e6e88686","toSide":"bottom"},
		{"id":"7b841622313d7f22","fromNode":"033bd95d29fb1bd8","fromSide":"left","toNode":"10546463f6f462dd","toSide":"right"},
		{"id":"bc01c77acec7fd9d","fromNode":"033bd95d29fb1bd8","fromSide":"left","toNode":"48baf6027cb9b1fb","toSide":"right"},
		{"id":"97ee3277b29d8c56","fromNode":"c08e3d70444f37a8","fromSide":"left","toNode":"374730ea6e8d5b3a","toSide":"right"},
		{"id":"943cdbd9ed5dac2f","fromNode":"10546463f6f462dd","fromSide":"left","toNode":"c2df5bf426c9e5da","toSide":"right"},
		{"id":"9b2fe539d87a7c47","fromNode":"c2df5bf426c9e5da","fromSide":"left","toNode":"a917fa7a67d05f37","toSide":"right"},
		{"id":"d2a799ad08cd8410","fromNode":"10546463f6f462dd","fromSide":"left","toNode":"b0b19e3eba04a1f4","toSide":"right"},
		{"id":"090db1dfaf60a4b9","fromNode":"c2df5bf426c9e5da","fromSide":"bottom","toNode":"b0b19e3eba04a1f4","toSide":"top"},
		{"id":"20e409b5ee5084de","fromNode":"b0b19e3eba04a1f4","fromSide":"left","toNode":"4a5d3e9159bb48f4","toSide":"right"},
		{"id":"b4c1be039a1278be","fromNode":"4a5d3e9159bb48f4","fromSide":"left","toNode":"a8ab951f3c5c0e8f","toSide":"right"},
		{"id":"34978a6e48f2cad3","fromNode":"10546463f6f462dd","fromSide":"top","toNode":"205c68fa78ad62a8","toSide":"bottom"},
		{"id":"c0fce7d7a523299c","fromNode":"10546463f6f462dd","fromSide":"left","toNode":"8411d47feb4ccd4a","toSide":"right"},
		{"id":"244f5e725b0b05ef","fromNode":"a8ab951f3c5c0e8f","fromSide":"left","toNode":"8ab38c1422963ca9","toSide":"right"},
		{"id":"2f31c5a5d377f195","fromNode":"48baf6027cb9b1fb","fromSide":"left","toNode":"84e33f30ca11a5c0","toSide":"right"},
		{"id":"f1f4bf5e5ff50fe6","fromNode":"84e33f30ca11a5c0","fromSide":"left","toNode":"8a37bedbd282f0df","toSide":"right"},
		{"id":"53b4e646150834b6","fromNode":"033bd95d29fb1bd8","fromSide":"left","toNode":"178bdf8a6493081f","toSide":"right"},
		{"id":"7e5dc14b0190f081","fromNode":"8a37bedbd282f0df","fromSide":"left","toNode":"26cc4c01193cef45","toSide":"right"},
		{"id":"73f91f22e86ec136","fromNode":"a8ab951f3c5c0e8f","fromSide":"bottom","toNode":"26cc4c01193cef45","toSide":"top"}
	]
}