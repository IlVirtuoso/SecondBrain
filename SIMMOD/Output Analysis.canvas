{
	"nodes":[
		{"id":"1fb92f5716a05bcc","type":"text","text":"## Terminating conditions \ndepending on statistics chosen they can be expressed in term of simulation time or number of processed events. \n\nin the case of an SSQ we want to estimate: \n- the average number of customers in the system up to time T (1)\n- the average waiting time experienced by the first N customers (2)\n\nFormally \n1) state variable $n(\\cdot)$ is known as stochastic process. typical objective estimate time-averaged transient statistic $\\bar{n}(T)=\\frac{1}{T} \\int^{T}_{0}n(t) dt$ .\n2) $W_i$ also is a stochastic process. typical objective estimate sample-averaged transient statistic $\\bar{W}(N)= \\frac{1}{N}\\sum^{N}_{i=1}W_i$ \n","x":-280,"y":280,"width":580,"height":420,"color":"2"},
		{"id":"6538a838c6494722","type":"text","text":"[[Interval estimation.canvas|Interval estimation]]","x":1580,"y":-520,"width":200,"height":60,"color":"2"},
		{"id":"e7c5ed1f4adca3b7","type":"text","text":"## Replication and interval estimation\nsuppose the simulation is replicated p times, each time generating a state time history $x_i(t)$ -> $\\bar{x_i}(T)=\\int^{T}_{0}x_i(t) dt$ where i is the replication index.\n\n- Each data point $\\bar{x}_i(T)$ is a indipendent observation of the RV $\\bar{X}(T)$ \n- if p is large enough, pdf of $\\bar{X}(T)$ can be estimated from histogram of $\\bar{x}_i(T)$  \n\nSpecifically if we want $E[\\bar{X}(T)]$ :\n- a point estimate is available as a sample average $\\hat{\\micro}=\\frac{1}{p}\\sum^{p}_{i=1}\\bar{x}_i(T)$ \n- an interval estimate for $E[\\bar{X}(T)]$ can be calculated: Using the [[Interval estimation.canvas|Interval estimation]] technique. This requires sample mean and std deviation of $\\bar{x}_i(T)$ , this can be used to estimate $\\bar{n}(T)$ and $\\bar{W}(N)$ \n\nlet $n(T)$ be the number of customers in the system at time T, suppose we want $E[n(T)]$ \n- n(T) is a RV and the result of the simulation at time T is an instance of RV\n- in general the distribution of n(T) is far from being an approx Normal \n- repeating the simulation several times produces data that are hard to analyze with standard confidence interval techniques.\n- subdivide the sample of size p into p/K subsample is a good way to compute the average results (with proper confidence intervals) that can be used as a set of measure for other computations.","x":1330,"y":-360,"width":700,"height":640,"color":"1"},
		{"id":"1e27b80b5d92dc0f","type":"text","text":"## Probability of lying in a fixed interval \n\nAssume a sample of p observation of an RV $Y_i \\in Y,i=1...p$ coming from p independent observation, we want to estimate the probability that Y takes values within interval I\n$\\psi = Prob\\{Y \\in I\\}$ , let X be an RV derived from Y $X_i= \\begin{cases} 1 \\ \\ if \\ Y_i \\in i \\\\ 0\\end{cases}$   then $E[X]=E[X_i]=\\psi$ \n\ndefine m to be the number of sample components $Y_i$ that belong to I -> $m = \\sum^{p}_{i=1}X_i$ \n\nThe unbiased estimate of this prob is $\\psi = \\frac{1}{p}\\sum^{p}_{i=1}X_i=\\frac{m}{p}$ where $E[\\psi]=\\frac{1}{p}\\sum^{p}_{i=1}E[X_i]=\\psi$ \nand $VAR[\\hat{\\psi}]=\\frac{\\psi(1-\\psi)}{p}$ \n\nm has binomial distribution with parameter $\\psi$  --> $Prob\\{m=k\\}= \\frac{p!}{k!(p-k)!} \\psi^k(1-\\psi)^{p-k}$ \nexpected value and variance of this RV are then \n$E[m]=p \\psi$  and $VAR[m]=p \\psi(1-\\psi)$ \n\nestimating $\\psi$ is equal to estimating the parameter of a binomial distribution when $\\psi$ is the probability of success $Prob\\{\\hat{\\psi}_L \\leq \\psi \\leq \\hat{\\psi}_U\\}$  where $\\hat{\\psi}_L$ and $\\hat{\\psi}_U$ can be obtained from resolving the following 2 equations \n\n$\\sum^{p}_{k=m}[\\frac{p!}{k!(p-k)!} \\psi_L^k(1-\\psi_L^k)^{p-k}] = \\frac{\\alpha}{2}$  for $\\psi_L$      \n$\\sum^{m-1}_{i=0}[\\frac{p!}{k!(p-k)!} \\psi_U^k(1-\\psi_U^k)^{p-k}] = \\frac{\\alpha}{2}$  for $\\psi_U$    \n\nwhen  p is large and both m and p-m are > 5  a simpler way to get the confidence interval for $\\psi$ is to use a normal distribution as an approximation of the binomial. So we can claim that $\\hat{\\psi}$ has a normal distribution with mean $\\psi$ and variance $\\frac{\\psi(1-\\psi)}{p}$  \n\nso with the following auxiliary variable $Z=\\frac{\\hat{\\psi} - \\psi}{\\sqrt{\\psi(1-\\psi}/p}$ , that has a standard normal distribution we can search $Pr(-z_{\\alpha/2} \\leq Z \\leq z_{\\alpha/2}) = 1-\\alpha$  and then the desired confidence interval becomes \n\n$$\nPr\\{\\frac{m}{p}-z_{\\alpha/2}\\sqrt{\\frac{m(p-m)}{p}} \\leq \\psi \\leq Pr\\{\\frac{m}{p}+z_{\\alpha/2}\\sqrt{\\frac{m(p-m)}{p}}\\}= 1-\\alpha\n$$\n","x":1325,"y":440,"width":710,"height":820,"color":"1"},
		{"id":"14aeb15597035112","type":"text","text":"## Finite horizon simulations  \nA finite-horizon discrete event simulation is one for which the simulated operational time is finite. they are also know as terminating simulations. Often the system state is assumed to be idle at the beginning and at the end of the simulation. The terminating condition can be specified by the close the door time.\n- Transient system statistics are produced by this simulation.\n- Initial conditions affect finite horizon statistics\n- No need to assume a static environment \n","x":-280,"y":-200,"width":580,"height":320,"color":"4"},
		{"id":"5f7d906f79d18ccf","type":"text","text":"## Infinite horizon simulations (steady state)\nSteady state statistics are produced by this type of simulations, in this case the initial conditions doesn't affect the statistics produced (system loses memory of the initial state). Thus the system environment is assumed to remain static.","x":-280,"y":-560,"width":580,"height":200,"color":"4"},
		{"id":"ed464e34ce17dd95","type":"text","text":"## The length of the initial transient period \nThe initial condition must not:\n- affect the steady state behaviour \n- require a very long initial simulation before getting a stable condition. \n\nThe effect of those observation is that we must discard a long initial simulation.\nThe identification of the conditions is a difficult task that can only be addressed with preliminary simulations (pilot simulations).  The idea is to perform many simulation and collect statistics at different simulation times in order to construct samples that can be used to compute the probability distributions at these instant. So when compared they can be assumed as the steady state distribution of the process\n","x":1260,"y":-1580,"width":660,"height":360,"color":"5"},
		{"id":"cde292e24b57a8dd","type":"text","text":"## Comparing distributions \n- let $Y(t)$ be # of person in the system at time t and assume we made many observation $t_1,t_2,...,t_n$ --> $\\{Y_i(t_n),i=1...p\\} \\ \\ n=1,2,3...$ \n- let $m_k(t_n)$ be # of times $Y_i(t_n) = k$ --> $\\{m_k(t_n),k=1...N_{max}\\}$ \n- let $\\psi_k(t_n)$ be P of observing k person in the system at time $t_n$ \nThus we can compute $\\{\\psi_k(t_n)=\\frac{m_k(t_n)}{p}\\} \\ \\ k=1...N_{max}$ where at most $N_{max}$ customers have been observed in the system. \n\nThe initial transient period is defined as the value of index n where the difference between $t_n$ and $t_{n+1}$ becomes smaller than a certain threshold \n$$\nt_n:min_n\\{\\frac{\\sum^{N_{max}}_{k=1}[\\psi_k(t_n)-\\psi_k(t_{n+1}]^2}{N_{max}} < \\epsilon\\}\n$$\n","x":2040,"y":-2260,"width":660,"height":440,"color":"1"},
		{"id":"e4d876f751076206","type":"text","text":"## Comparing moments \ncomparing distribution need a big amount of data, a reasonable compromise is to compare moments instead of distributions. In this case we can compute \n$$\nt_n^{[h]}:min_n\\{|\\frac{\\sum^{p}_{i=1}[Y_i(t_n)]^h}{p} - \\frac{\\sum^{p}_{i=1}[Y_i(t_{n+1})]^h}{p}|<\\epsilon\\}\n$$\nDifferent moments yields different informations, so the actual length may be computed as $t_n:max_h\\{t_n^{[h]}\\}$ , the cost is high so reducing the compute cost to just the first moments is a good option. Averages computed at different times may oscillate, so we can compute moving averages :\n\nlet $\\hat{\\micro}(t_n)$ be the sample calculated at time $t_n$ --> $\\hat{\\micro(t_n)}= \\frac{\\sum^{p}_{i=1}Y_i(t_n)}{p}$ \nfrom these derived quantities we can compute moving averages over 2L+1 subsequent instants $\\hat{\\micro}^{[L]}(t_n)= \\frac{\\sum^{L}_{i=-L}\\hat{\\micro}(t_{n+i})}{2L+1}$ ","x":1260,"y":-2260,"width":660,"height":440,"color":"1"},
		{"id":"5af1f9b427276358","type":"text","text":"## Comparing auto correlation\nwe can identify the length of the initial period by measuring auto correlation: i.e measure the influence accross observations \n\nConsider a sequence of RVs $\\{Y_1,Y_2,...,Y_n\\}$ :\n- Compute the auto covariance function $Cov(d)= \\frac{1}{N-d}\\sum^{N-d}_{i=1}(Y_i-E[Y])(Y_{i+d}-E[Y])$\n- Since we don't know $E[Y]$ we can approximate using an experimental covariance $\\phi(d)=\\frac{1}{N-d-1}\\sum^{N-d}_{i=1}(Y_i-\\bar{Y})(Y_{i+d}-\\bar{Y})$  \nwith the experimental mean $\\bar{Y}$ expressed as always.\n\n$\\phi(0)$ is the usual variance $\\hat{s}^2$, we can thus compute the experimental auto-correlation \n$\\rho(d)=\\frac{\\phi(d)}{\\hat{s}^2}$  that is a normalized auto covariance with interval values (-1,1), values next to 0 mean that influence accross measures are negligible. Thus we can search for this value to state where is the end of the initial transient period $d_0=min_d\\{|\\rho(d)| \\leq \\epsilon \\}$ \n\n\n","x":440,"y":-2320,"width":660,"height":500,"color":"1"},
		{"id":"27dec0e4325100d4","type":"text","text":"## The challenge\nusing $\\{W_n:n =1,2,3,...\\}$ suppose we are interested in estimating the waiting time distribution in steady state: $\\lim_{n \\rightarrow \\infty} Prob\\{W_n \\leq x\\} = F(x)$.\nAs in the case of transitory state we are interested in calculate expected value and variance of this value. \n\nIn this case we don't need independent replications, because all RVs have all the same distribution. There are elements to take in consideration however:\n- The observation of the RV must be made after a set of initial observations\n- The observations made in a single simulation are in general highly correlated, and so many of the simple statistical method are ineffective since there is no independence\n\n","x":520,"y":-1130,"width":660,"height":380,"color":"1"},
		{"id":"705924e1c08aaf8f","type":"text","text":"## Overcome statistical dependency amongst observation \n\nif we have a set of indipendent variables $Y_n$ and we want to estimate the characteristics, we can consider this set as a set of instance of the same RV but highly correlated, thus we need a method to reduce the dependency amongst those instances:\n\n- independent replications \n- Batch means\n- Regeneration points ","x":2120,"y":-1107,"width":660,"height":335,"color":"5"},
		{"id":"892b702f101ad196","type":"text","text":"## Indipendent repications\nthe samples collected in a set of replication are not independent (output are correlated), so is possible to calculate mean and variance but they are not independent, so is necessary a system to overcome this problem.\n\nThus the simulation can be repeated varying only the seed of the generator, the totality of the replication is an ensemble or sample, the seed must be chosen so that there is no overlapping between simulations, tipically the final state of the previous simulation is used as seed for the new one.","x":480,"y":-210,"width":580,"height":340,"color":"1"},
		{"id":"d227042735bc8cac","type":"text","text":"## Waiting time of the K-th customer (jackknifing)\n$W_k^{[i]} :i =1,2,...p$ = sample of measurement of waiting time of the k-th customer (only).\n\n$\\bar{W}_k=\\frac{1}{p}\\sum^{p}_{i=1}W_k^{[i]}$  ,     $\\hat{s}^2_{W_k}=\\frac{1}{p-1}\\sum^{p}_{i=1}(W_k^{[i]} - \\bar{W}_k)^2$ \n- we obtain confidence interval for $\\micro = E[W_k]$  --> $Pr\\{\\bar{W}_k-t_{(p-1,\\frac{\\alpha}{2})} \\frac{\\hat{s}_{W_k}}{\\sqrt{p}} \\leq \\micro \\leq \\bar{W}_k+t_{(p-1,\\frac{\\alpha}{2})} \\frac{\\hat{s}_{W_k}}{\\sqrt{p}}\\} \\approx (1-\\alpha)$ \n- we compute the point estimate of the variance \n$\\hat{s}^2 = \\frac{1}{p-1}\\sum^{p}_{i=1}(W_k^{[i]}-\\bar{W}_k)^2$     $E[\\hat{s}^2]=\\sigma^2$ \n- subdivide the original sample into p sub sample of size p-1 items $(W_k)_j$ \n$\\bar{W_k}_j=\\frac{1}{p-1}\\sum^{p}_{i=1;i \\neq j}W_k^{[i]}$        $\\hat{s}^2=\\frac{1}{p-2}\\sum^{p}_{i=1;i \\neq j}(W_k^{[i]})^2 - \\frac{p-1}{p-2}\\bar{(W_k)_j^2}$  \n\ndefine $Z_j=p \\hat{s}^2- (p-1)\\hat{s}_j^2$  knowing $E[Z_j]=\\sigma^2$ we can form a new sample of $Z_i$ \n$\\bar{Z}=\\frac{1}{p}Z_j$     $\\hat{s}_Z^2=\\frac{1}{p-1}\\sum^{p}_{j=1}(Z_j-\\bar{Z})^2$ \n\nwe can then define $\\Upsilon = \\frac{(\\bar{Z}-\\sigma^2)}{s_Z/\\sqrt{p}}$ , and show that is a RV distributed as a t-student with p-1 grade of freedom  and then obtain the confidence interval for $\\sigma^2$ \n$$\nPr\\{\\bar{Z} - t_{(p-1,\\frac{\\alpha}{2})} \\frac{\\hat{s}_Z}{\\sqrt{p}} \\leq \\sigma^2 \\leq \\bar{Z} + t_{(p-1,\\frac{\\alpha}{2})} \\frac{\\hat{s}_Z}{\\sqrt{p}} \\} \\approx (1-\\alpha)\n$$\n\nthis method is know as jackknifing\n\n","x":1330,"y":1600,"width":700,"height":580,"color":"1"},
		{"id":"122347255918062a","type":"text","text":"## Mean and variance \nDetermined $n_0$ we run p independent simulations and obtain a sequence of variable of interests \n$\\{ Y_{j1},Y_{j2},...,Y_{jn_0},...,Y_{jk},...,Y_{jN}:j=1...p \\}$   from each of this realization we construct measures that become the components of our sample. \n\nAs for the finite horizon analysis we can easily compute interval estimates. Starting from the mean: $\\bar{Y}_j = \\frac{1}{N-n_0}\\sum^{N}_{k=n_0+1}Y_{jk}$, the data can be then organized in this manner \n$$\n\\begin{aligned}\n\\{ Y_{11},Y_{12},...,Y_{1n_0},...,Y_{1k},...,Y_{1N}\\} \\Rightarrow \\bar{Y}_1\n\\\\\n\\{ Y_{21},Y_{22},...,Y_{2n_0},...,Y_{2k},...,Y_{2N}\\} \\Rightarrow \\bar{Y}_2\n\\\\\n\\{ Y_{p1},Y_{p2},...,Y_{pn_0},...,Y_{pk},...,Y_{pN}\\} \\Rightarrow \\bar{Y}_p\n\\end{aligned}\n$$\nout of these values we compute \nthe unbiased sample mean $\\hat{\\micro}=\\bar{Y} =\\frac{1}{p}\\sum^{p}_{j=1}\\bar{Y}_j$ and variance  $\\hat{s}^2 = \\frac{1}{p-1}\\sum^{p}_{j=1}(\\bar{Y_j} - \\bar{Y})^2$ \nwhen $N-n_0$ is large those RVs can be assumed to have a normal distribution and so the confidence interval is $Pr\\{\\bar{Y} - t_{p-1,\\alpha/2}\\sqrt{\\hat{s}^2/p} \\leq \\micro \\leq \\bar{Y} + t_{p-1,\\alpha/2}\\sqrt{\\hat{s}^2/p}\\} \\approx 1- \\alpha$  \nAs usual is possible to control the size of the confidence interval by controlling the number of replications P and the number of observations N that has important effects on $\\hat{s}^2$ \n\nWhen p>40 the t-student is approximate as a Normal so that $t_{p-1,\\alpha/2}$ can be replaced with $z_{\\alpha/2}$ \n","x":3470,"y":-331,"width":730,"height":583,"color":"1"},
		{"id":"41aa2abc2f91922b","type":"text","text":"## Probability of falling within an interval \nestimate as the other case $\\psi_n=Pr\\{Y^{[n]} \\in I\\}$ , where $Y^{[n]}$ is the observation of interest during a simulation of length n. we can assume that $\\psi = \\lim_{n \\rightarrow \\infty} \\psi_n$ . After having determined $n_0$ we can assume the process to be stationary and so $\\psi_n \\approx \\psi$ . \n\nGiven $n_0$ we perform p runs that will provide an interval estimate for $\\psi$  and yield a set $\\{Y_{ij} :i=1..p;j=1...N\\}$  assuming $N>>n_0$ . From each simulation we compute the unbiased estimate of the desired prob $\\hat{\\psi}_i=\\frac{v_i}{N-n_0}$ . where $v_i$ is # of times Y fells in I. Thus $\\hat{\\psi}_i$ values obtained are independent --> $E[\\hat{\\psi}_i]=\\psi$ \n\nWe can compute then the sample mean and variance:\n$\\hat{\\psi}= \\frac{1}{p}\\sum^{p}_{i=1}\\hat{\\psi}_i$   ,    $\\hat{s}^2(\\hat{\\psi})=\\frac{1}{p-1}(\\hat{\\psi}_i - \\hat{\\psi})^2$ . Let's define $Z = \\frac{\\hat{\\psi}-\\psi}{\\sqrt{\\hat{s}^2(\\hat{\\psi})/p}}$ that has a t-student(p-1). \nAn interval estimate is expressed as $Pr\\{\\hat{\\psi}-t_{p-1,\\alpha/2}\\frac{s(\\hat{\\psi})}{\\sqrt{p}} \\leq \\psi \\leq \\hat{\\psi}+t_{p-1,\\alpha/2}\\frac{s(\\hat{\\psi})}{\\sqrt{p}}\\}$ where as usual if p is large we can replace $t_{p-1,\\alpha/2}$ with $z_{\\alpha/2}$ .","x":3465,"y":570,"width":740,"height":561,"color":"1"},
		{"id":"482c65a1b5cdfd13","type":"text","text":"## independent replications\nthe components of the sample are obtained by running the simulations many times with different random generator seeds, with identical initial conditions, disregarding the data obtained by the initial simulation run","x":3590,"y":-680,"width":490,"height":253,"color":"5"},
		{"id":"64466745d12d15df","type":"text","text":"## Batch means\nthe components of sample are collected by a single simulation run after having discarded the data obtained by the transient period and subdividing the data collected into subsamples which are assumed to be approximately independent because of the inter collection time long. ","x":3590,"y":-1043,"width":530,"height":207,"color":"5"},
		{"id":"5020622981f85fb7","type":"text","text":"## Mean and variance \nwe can compute sample and mean with this formula \n$$\n\\bar{Y}_j=\\frac{1}{N-n_0}\\sum^{n_0+(j+1)*m}_{k=n_0+j*m+1}Y_{jk}\n$$\nthe data can organized in this way\n$$\n\\begin{aligned}\n\\{ Y_{11},Y_{12},...,Y_{1n_0},...,Y_{1k},...,Y_{1N}\\} \\Rightarrow \\bar{Y}_1\n\\\\\n\\{ Y_{21},Y_{22},...,Y_{2n_0},...,Y_{2k},...,Y_{2N}\\} \\Rightarrow \\bar{Y}_2\n\\\\\n\\{ Y_{p1},Y_{p2},...,Y_{pn_0},...,Y_{pk},...,Y_{pN}\\} \\Rightarrow \\bar{Y}_p\n\\end{aligned}\n$$\nand then apply the techniques used before","x":4390,"y":-225,"width":800,"height":372,"color":"3"},
		{"id":"955e71b227bca153","type":"text","text":"## Discard the transient period\nin order to identify the transient period, the auto covariance technique is recommended. Let $Y_{i,j}$ be the j-th observation belonging to the i-th sequence. Let's generate 2 subsequences $\\{Y_{i,j}:j=1...m\\}$ and $\\{Y_{i+1,j}:j=1...m\\}$ with $m>n_0$ , since this precondition those 2 subsequences are independent, repeating this consideration for the pair $\\{Y_{i+1,j};Y_{i,j}\\}$ j=2...m we can consider the whole sample made of independent observations. Thus we can apply the techniques used for the independent replication here as well","x":4460,"y":-1073,"width":660,"height":268,"color":"3"},
		{"id":"3ebce3d50050fc9f","type":"text","text":"## Regenerative method\nthe components of the sample are obtained by a single simulation run splitted into regenerative cycles. Defined as regeneration points where the simulated stochastic process naturally loses the memory of the past.","x":3590,"y":-1580,"width":490,"height":260,"color":"5"},
		{"id":"b9fc54566286da56","type":"text","text":"## Initial conditions\n- The component of the sample are derived from successive regeneration cycles\n- Regenerations cycles are random length subsequences identified within the simulation run, starting the simulation from one of these regeneration points it's possible to avoid wasting the initial part of the simulation. \n- RVs in different sequences are independent and equally distributed \n- If the sequence is regenerative and certain weak conditions hold the sequence has a steady state.\n![[Pasted image 20231118103525.png]]\nfrom this queue we can take the following subsequences $\\{W_1,W_2,W_3,W_4,W_5,W_6,W_5\\}$ , $\\{W_8,W_9\\}$ , $\\{W_{10},W_{11},W_{12},W_{13}\\}$  characterized by the fact that the first element (sequence) is always the waiting time of a customer that arrives and find the queue empty. These subsequences are called regeneration cycles. The data can be organized as p subsequences expressed in this form\n$$\n\\begin{aligned}\n\\{ W_{11},W_{12},...,W_{1k},...,W_{1m_1}\\} \n\\\\\n\\{ W_{21},W_{22},...,W_{2k},...,W_{2m_2}\\}\n\\\\\n\\{ W_{p1},W_{p2},...,W_{pk},...,W_{pm_p}\\}\n\\end{aligned}\n$$","x":4420,"y":-1773,"width":890,"height":646,"color":"3"},
		{"id":"ba6e055fef30e96a","type":"text","text":"## Initial considerations\nLet $A_j=\\sum^{m_j}_{k=1}W_{jk}$ be the sum of the waiting times observed during the j-th regeneration cycle. Where $m_j$ is the number of customers served in the j-th cycle and can be used as a measure of length of the cycle. Thus from each regeneration cycle we get $\\bar{W}_j=\\frac{1}{m_j}\\sum^{m_j}_{k=1}W_{jk}=\\frac{A_j}{m_j}$ that is the ratio between 2 correlated variables. \n\nIn a generic form $A_j= \\int^{\\beta_j}_{\\beta_{j-1}}n(t)dt$ can be expressed as integral of n(t) computed in the j-th regeneration cycle. Denoting with $\\delta_j=\\beta_j-\\beta_{j-1}$ the length of the cycle we get a point estimate $\\bar{n}_j=\\frac{1}{\\delta_j}\\int^{\\beta_j}_{\\beta_{j-1}}n(t)dt=\\frac{A_j}{\\delta_j}$ .\nRunning the simulation up to the point of observing p regeneration cycles we collect samples that cannot be used in a standard way because of their correlation. Such that the distribution of $\\bar{W}_i$ is different from $\\bar{W}$. It is thus mandatory taking into account the correlated nature of the measures coming from different regeneration cycles. \n\nGiven a random variable $Y$ that we measure we can summarize the outcomes with a series of independent and identically distributed random pairs $\\{(A_1,v_1),...,(A_p,v_p)\\}$ : where \n- $A_j$ is the sum or integral computed over the j-th regeneration cycle \n- $v_j$ is the length of the j-th regeneration cycle expressed as the number of occurrences of $Y$ or as the distance in time between its end points. \n\n","x":5800,"y":-1688,"width":890,"height":476,"color":"1"},
		{"id":"b1fa4f331e5fc959","type":"text","text":"## Point estimate \nunder some conditions is possible to show $E[\\hat{r}] = r = \\frac{E[A_1]}{E[v_1]}=\\frac{E[A_j]}{E[v_j]}$ so that $\\hat{r}$ is the estimate point of interest. \nLet $Z_j=A_j-rv_j$  for which $E[Z_j]=0$  and $VAR[Z_j]=VAR[A_j]-2rCOV[A_j,v_j]+r^2VAR[v_j]$  , the covariance is present due to the mutual dependence between elements of our ratio. \nWe can define $\\bar{Z} = \\frac{1}{p}\\sum^{p}_{j=1}Z_j=\\bar{A}-r \\bar{v}$  so that $E[\\bar{Z}]=0$ and $VAR[\\bar{Z}]=\\frac{VAR[Z_j]}{p}=\\frac{\\sigma^2_Z}{p}$.\nThe central limit theorem allows to state $\\frac{\\bar{Z}}{\\sigma_z/\\sqrt{p}}=\\frac{\\bar{A}-r \\bar{v}}{\\sigma_Z/\\sqrt{p}}= \\frac{\\bar{A}/\\bar{v}-r}{\\sigma_Z/(\\bar{v}\\sqrt{p})}=\\frac{\\hat{r}-r}{\\sigma_Z/(\\bar{v}\\sqrt{p})}$  has a std normal distribution. So we can compute $Pr\\{\\hat{r}-z_{\\alpha/2}\\frac{\\sigma_Z}{\\bar{v}\\sqrt{p}} \\leq r \\leq \\hat{r}+z_{\\alpha/2}\\frac{\\sigma_Z}{\\bar{v}\\sqrt{p}}\\} \\approx 1-\\alpha$ but $\\sigma^2_Z$ is unknown so we must use sample variance \n$\\sigma^2_Z \\approx \\hat{s}^2_Z=\\hat{s}^2_A-2\\hat{r}\\hat{s}_{Av}+\\hat{r}^2\\hat{s}^2_v$ so that the solution has not std normal but a t-student distribution and then the confidence interval becomes \n$$\nPr\\{\\hat{r}-t_{1,\\alpha/2}\\frac{\\hat{s}_Z}{\\bar{v}\\sqrt{p}} \\leq r \\leq \\hat{r}+t_{1,\\alpha/2}\\frac{\\hat{s}_Z}{\\bar{v}\\sqrt{p}} \\} \\approx 1-\\alpha\n$$\n ","x":7000,"y":-2560,"width":890,"height":388,"color":"1"},
		{"id":"7c8e36e60db04d32","type":"text","text":"## Width of confidence interval \nto compute the previous conf interval, we must estimate the variance of $Z_j$ \n- $VAR[A_j] \\approx \\hat{s}^2_A=\\frac{1}{p-1}\\sum^{p}_{j=1}(A_j-\\bar{A})^2=\\frac{1}{p-1}[\\sum^{p}_{j=1}A^2_j-p \\bar{A}^2]=\\frac{1}{p-1}\\{\\hat{S}_{AA}-p \\bar{A}^2\\}$  \n- $COV[A_j,v_j] \\approx \\hat{s}_{av}=\\frac{1}{p-1}\\sum^{p}_{j=1}(A_j-\\bar{A})(v_j-\\bar{v})=\\frac{1}{p-1}[\\sum^{p}_{j=1}A_jv_j-p \\bar{A}\\bar{v}] = \\frac{1}{p-1}\\{\\hat{S}_{Av} - p \\bar{A}\\bar{v}\\}$   \n- $VAR[v_j] \\approx \\hat{s}^2_v = \\frac{1}{p-1}\\sum^{p}_{j=1}(v_j-\\bar{v})^2=\\frac{1}{p-1}[\\sum^{p}_{j=1}v^2_j-p \\bar{v}^2]=\\frac{1}{p-1}\\{\\hat{S}_{vv}-p \\bar{v}^2\\}$   \nwhere\n$\\hat{S}_A= \\sum^{p}_{j=1}A_j$ , $\\hat{S}_{AA} = \\sum^{p}_{j=1}A^2_j$ , $\\hat{S}_{Av}=\\sum^{p}_{j=1}A_jv_j$ ,$\\hat{S}_v= \\sum^{p}_{j=1}v_j$ , $\\hat{S}_{vv} = \\sum^{p}_{j=1}v^2_j$, $\\hat{r}=\\frac{\\hat{S}_A}{\\hat{S}_v}$ \n\\begin{align}\nX_{01} \\Rightarrow \\{U_1\\} \\Rightarrow Y_{11}; && X_{01} \\Rightarrow \\{U_1^*\\} \\Rightarrow Y_{21} \\\\\n...\\\\\nX_{0p} \\Rightarrow \\{U_p\\} \\Rightarrow Y_{1p}; && X_{0p} \\Rightarrow \\{U_p^*\\} \\Rightarrow Y_{2p}\n\\end{align}\nrecalling $\\sigma^2_Z \\approx \\hat{s}^2_Z=\\hat{s}^2_A-2\\hat{r}\\hat{s}_{Av}+\\hat{r}^2\\hat{s}^2_v$ we can write $\\hat{s}^2_Z=\\frac{1}{p-1}\\{\\hat{S}_{AA}-2\\hat{r}\\hat{S}_{Av}+\\hat{r}^2\\hat{S}_{vv}\\}$  so that the width can be \n$$\n\\Delta= \\frac{\\hat{s}_Z}{\\bar{v}\\sqrt{p}}=\\sqrt{\\frac{p}{p-1}}\\frac{\\sqrt{\\hat{S_{AA}-2\\hat{r}\\hat{S}_{Av}+\\hat{r}^2+\\hat{S}_{vv}}}}{\\hat{S}_v}\n$$\ndespite the complexity of computing this confidence interval \n$Pr\\{\\hat{r}-t_{1,\\alpha/2}\\Delta \\leq r \\leq \\hat{r}+t_{1,\\alpha/2}\\Delta \\} \\approx 1-\\alpha$ the values needed $A_j,A^2_j,v_j,v^2_j,A_jv_j$ can be accumulated at the end of each regeneration cycle. ","x":8180,"y":-2618,"width":890,"height":504,"color":"1"},
		{"id":"52cc6cc700463e75","type":"text","text":"## Interval estimation of simulated random variables \nthe regenerative method is well suited for interval estimation of functions of simulated RVs, the unique requirement is to define well the expression of $A_j$ . For example \n- average queue length $A_j=\\int^{\\beta_j}_{\\beta_{j-1}}N(t)dt$  $v_j=\\beta_j-\\beta_{j-1}$ \n- second moment of queue length $A_j=\\int^{\\beta_j}_{\\beta_{j-1}}N(t)^2dt$  $v_j=\\beta_j-\\beta_{j-1}$ \n- mean waiting time $A_j=\\int^{\\beta_j}_{\\beta_{j-1}}N(t)dt$  $v_j=C_j$\n- probability of finding k customers in queue $A_j=\\int^{\\beta_j}_{\\beta_{j-1}}I_k(t)dt$   $v_j=\\beta_j-\\beta_{j-1}$ Ik is # of times N(t)=k\n- Average cost of waiting $A_j=\\int^{\\beta_j}_{\\beta_{j-1}}R(N(t)) dt$        $v_j=\\beta_j-\\beta_{j-1}$ where R(k) is cost rate due to the presence of k customers in system \n\n","x":9380,"y":-2535,"width":890,"height":338,"color":"1"},
		{"id":"701d315c27080880","type":"text","text":"## Finding regeneration points\na regeneration point correspond to a state reached by the system when the future evolution can be considered as a replica of the previous one. When the system gets to such a point we can answer question on its future behavior without the need of information on its past, thus a regeneration point is defined by the occurrence of a particular event in a defined state. ","x":7000,"y":-1073,"width":560,"height":273,"color":"1"},
		{"id":"6802d76c504be239","type":"text","text":"## Minimum among Neg Exp RVs\nGiven 2 RVs with neg exp distribution \n$$\n\\begin{align}\nf_X(x)=\\lambda e^{\\lambda-x}\\  \\ \\ (x \\geq 0)  && f_Y(y)=\\delta e^{\\delta y} \\ \\ \\ (y \\geq0)\n\\end{align}\n$$\nDefine new RV $Z=min(X,Y)$ :\n- Z is neg exp with parameter $\\lambda+\\delta$ \n- $F_Z(z)=1-e^{\\lambda z} e^{-\\delta z}= 1- e^{-(\\lambda+\\delta)z}$ \n","x":6860,"y":-40,"width":700,"height":300,"color":"1"},
		{"id":"b069e04987fc939c","type":"text","text":"## Memory less property \nlet r(t) be the distribution of the remaining portion of X $r(t)=Pr\\{X >s+t|X>s\\}$ \nusing conditional probability we can show  $r(t)=\\frac{Pr\\{X>s+t\\}}{Pr\\{X>s\\}}$ Since X has a negative distribution we have :\n$r(t)=\\frac{e^{-\\lambda(s+t)}}{e^{-\\lambda(s)}}=e^{-\\lambda(t)}$ which says that the distribution of the remaining part of X is identical to that of X.\n\nThe memory less property can be formally expressed as \n$$\nPr\\{X> x+\\alpha|X>\\alpha\\}=Pr\\{X>x\\}\n$$\n\n","x":6850,"y":537,"width":720,"height":300,"color":"1"},
		{"id":"0690d55d9938c6f0","type":"text","text":"## Finding regeneration points in a network of queue\nthe discussion for FCFS easily extends to the case of more complex models. basic criteria remains interrupt the evolution of the model only in situations where there are no activities characterized by a general probability distribution. To make discussion simple let's use a queue with just 2 station in tandem with a fixed number N of customers , summarizing the criteria in the following table\n\n|Service time distribution of first queue| Service time distribution of second queue| Criteria for regeneration point |\n|----|----|-----------|\n|General|General|Any departure that leaves behin exactly n-1 customers from one of the two servers of the network|\n|markov(neg-exp)|General| any departure from the second server\n|General|markov| any departure from the first server\n|markov|markov|any departure in the system\n","x":7890,"y":-1688,"width":700,"height":500,"color":"1"},
		{"id":"b5c3b5294e37e235","type":"text","text":"## G/G/1 case \nno negative exponential, The only regeneration point is the arrival of a customer that finds the server idle. \n- if t be the time of arrival to an empty system --> the answer is $Pr\\{[\\delta=min(\\tau,\\sigma)]\\leq \\Delta\\}$  \n- if t is arrival of a new customer while another is already in service, let $\\rho$ be the remaining service time -->  $Pr\\{[\\delta=min(\\tau,\\rho)]\\leq \\Delta\\}$   \n- if t is time of departure of a customer let $v$ be the time required for the next arrival to happen --> $Pr\\{[\\delta=min(v,\\sigma)]\\leq \\Delta\\}$   \n","x":9130,"y":-913,"width":700,"height":356,"color":"1"},
		{"id":"7c8d74969460039c","type":"text","text":"## M/G/1 case \narrival process is Poisson and inter-arrival times have neg exp distribution , thus departure times are regeneration points because their occurrence requires the characterization of the remaining time\n$$\nPr\\{[\\delta'=min(v,\\sigma)]\\leq \\Delta\\} = Pr\\{[\\delta=min(\\tau,\\sigma)]\\leq \\Delta\\}\n$$\nThe same doesn't apply if we choose the time of the arrival of a customer that find the server busy \n$$\nPr\\{[\\delta* =min(\\tau,\\rho)]\\leq \\Delta\\} \\neq Pr\\{[\\delta=min(\\tau,\\sigma)]\\leq \\Delta\\} \n$$\n\n\n","x":9130,"y":-453,"width":700,"height":320,"color":"1"},
		{"id":"55763f9455c52111","type":"text","text":"## G/M/1 case \ndual to M/G/1 case:  any arrival time identifies a regeneration point because $\\rho$ has the same distribution of $\\sigma$ \n$$\nPr\\{[\\delta*=min(\\tau,\\rho)]\\leq \\Delta\\} = Pr\\{[\\delta=min(\\tau,\\sigma)]\\leq \\Delta\\}\n$$\n","x":9130,"y":-73,"width":700,"height":183,"color":"1"},
		{"id":"4205488d88fbe7f4","type":"text","text":"## M/M/1 case \nwhen both $\\tau$ and $\\sigma$ have neg exp distribution their memory less property ensure that any arrival or departure times are regeneration points\n$$\nPr\\{[\\delta'=min(v,\\sigma)]\\leq \\Delta\\} = Pr\\{[\\delta*=min(\\tau,\\rho)]\\leq \\Delta\\}= Pr\\{[\\delta'=min(\\tau,\\sigma)]\\leq \\Delta\\}\n$$\n","x":9130,"y":207,"width":700,"height":180,"color":"1"},
		{"id":"003c1b060de7ec21","type":"text","text":"## Negative exponential distribution \nlet X be a RV with neg exp distribution with parameter $\\micro=\\frac{1}{\\lambda}$\n$$\n\\begin{align}\nf_X(x)=\\lambda e^{-\\lambda x} && F_X(x)=1-e^{-\\lambda x}\\\\\nE[X] = \\micro=\\frac{1}{\\lambda} && VAR[X]=\\micro^2=\\frac{1}{\\lambda^2} && CV^2[X]=\\frac{VAR[X]}{(E[X])^2}=1\n\\end{align}\n$$\n### ","x":7890,"y":284,"width":700,"height":240,"color":"1"},
		{"id":"cc2f32b57f1d8d8d","type":"text","text":"## Finding regeneration points in FCFS single server system\nDeciding if the system is entered a regenerative conditions correspond to answer to:\n**\"what is probability that the system leaves the current state in less then $\\Delta$ time units\"?**\nwithout the needs of having information on the past of the system. Depending on the distribution of service time and inter arrival different consideration can be made:\n- G/G/1 queue: general distribution for both inter arrival and service time \n- M/G/1: inter arrival with neg exp and service time with general \n- G/M/1: inter arrival with general and service time with neg exp\n- M/M/1: both inter arrival and service time with neg exp distribution\nlets define the following variables \n- let $\\tau$ and $\\sigma$ be inter arrival and service time. \n- $\\rho$ and $v$ remaining service time and required time for next arrival ","x":7890,"y":-433,"width":700,"height":400,"color":"5"},
		{"id":"97de64b00abe2f63","type":"text","text":"## Identify regeneration cycles  \nwhen the model admits many regeneration points, one of them must be chosen as a reference and regeneration cycles begin and end when this point is reached. \n\nfor example if in a M/M/1 queue if we decide that a regeneration cycle start start when a departures leaves m customers we cannot end it if it leaves m+k customers. This is because the statistics collected must be identical and independent instances of the same RV.  identify regeneration cycles in a network is more difficult because we lose the memory less property.","x":9130,"y":-1582,"width":700,"height":288,"color":"1"},
		{"id":"2012e7e40eed9f6f","type":"text","text":"## Identify regeneration cycles  with passage times\nconsider the case of a sub system identified in a system. Assume a single entry point for this sub system, **we are interested in measuring the average time spent by customers in the sub system**. Candidate regeneration points are the arrival or a departure from the entry point of the sub system (because of memory less). If there exists stations outside the sub system with general time distributions they must be empty when the two previous events are considered. ","x":10400,"y":-1980,"width":700,"height":226,"color":"1"},
		{"id":"02d3c0c6a0517bdc","type":"text","text":"## Identify regeneration cycles  with tagged customer\nAll customers are statistically identical. This approach arbitrarily selects one customer in the system and follows its way through the system, recording: the time it enters $t_{en}$  and it exit $t_{ex}$ . The difference $\\tau=t_{ex}-t_{en}$ is a measure of the passage time.\n\nLet $\\tau_j^{[i]}$ be the j-th passage time of the tagged customer.\nLet $A^{[i]}=\\sum^{k^{[i]}}_{j=1}\\tau_j^{[i]}$ be the sum of the $k^{[i]}$ passage times. \n\nThe pair $(A^{[i]},k^{[i]})$ becomes the component of a sample of independent observation that can provide estimates with the regenerative method. ","x":10400,"y":-1229,"width":700,"height":333,"color":"1"},
		{"id":"5df4ad4f48c5f249","type":"text","text":"## Grouping regeneration cycles\nWhen there are many regeneration points it can happen that the chosen ones yield regeneration cycles that are too short. In this case we cannot rely on the central limit theorem stating that the distribution are \"quasi-normal\", if possible we must choose a new regeneration point that avoid this problem. \n\nIf not is possible to aggregate several regeneration cycles, the unique constraint is that the grouping criteria is always applied during the simulation run. Without conditioning its application on the specific characteristics of the regeneration cycles that need to be aggregated.","x":11400,"y":-1211,"width":700,"height":297,"color":"1"},
		{"id":"2f5ba528789510ce","type":"text","text":"## Terminating conditions\ndepending on the statistics chosen, the terminating conditions may assume different aspects. In general state variables $X(t)$ and $Y_i$ of a system are known formally as stochastic process. \n\nTipical objective are:\n-  time-averaged steady state statistics: $\\bar{x} = \\lim_{T \\rightarrow \\infty} \\frac{1}{T} \\int^{T}_{0}X(t)dt$ \n- sample-averaged steady state statistics: $\\bar{y}=\\lim_{N \\rightarrow \\infty} \\frac{1}{N} \\sum^{N}_{i=0}Y_i$ \nboth $\\bar{x}$ and $\\bar{y}$ are not random variables.\n\n","x":-280,"y":-1100,"width":580,"height":320,"color":"1"},
		{"id":"924f84dd5d5d2b21","type":"text","text":"## Antithetic variates \nAssume we want to estimate the expected value of an RV Y --> $Y(\\micro=E[Y])$ , suppose we run a simulation and produce a sample of 2p observations $\\{Y_1...Y_p,Y_{p+1}...Y_{2p}\\}$. In normal conditions we would retrieve $\\hat{\\micro}=\\bar{Y}=\\frac{1}{2p}\\sum^{2p}_{i=1}Y_i$  and $VAR[\\bar{Y}]=\\frac{\\sigma^2}{2p}$  knowing $E[\\bar{Y}]=\\micro$. \n\nSuppose to divide the sample in 2 sub samples of size p $\\{Y_1...Y_p,Y_{p+1}...Y_{2p}\\}= \\{Y_{11}...Y_{1p}\\},\\{Y_{21}...Y_{2p}\\}$ .\nLet $Z_i=\\frac{Y_{1i}+Y_{2i}}{2}$  that we use to obtain $\\bar{Z}=\\frac{1}{p}\\sum^{p}_{i=1}Z_i=\\bar{Y}$. The expected value and variance of $\\bar{Z}$ are:\n- $E[\\bar{Z}]=\\frac{E[Y_1]+E[Y_2]}{2}=\\micro$ \n- $VAR[\\bar{Z}]=\\frac{1}{p}VAR[\\frac{Y_1+Y_2}{2}]= \\frac{\\sigma^2}{2p}+\\frac{COV[Y_1,Y_2]}{2p}$  \nIf 2p of the original sample are independent then also those 2 sub samples are, thus $COV[Y_1,Y_2]=0$ and know that the introduction of the new variable doesn't perturb the experiment $VAR[\\bar{Z}]=VAR[\\bar{Y}]=\\frac{\\sigma^2}{2p}$ . \n\nIf they are correlated the division yield different results, if the variables $Y_1$ and $Y_2$ are negatively correlated the variance of $\\bar{Z}$ decrease and we obtain $VAR[\\bar{Z}] \\leq VAR[\\bar{Y}]$ . To induce this correlation is sufficient store the seeds used for the first p observations and use them to obtain the observations for the second sub sample. The unique constraint is using Antithetic sequence of random numbers. \n\n2 sequences of RN  $\\{U_i \\in (0,1);i=1...m\\}$  and $\\{U^*_i \\in (0,1);i=1...m\\}$  are Antithetic if $U_i^*=(1-U_i)$.\nLet $\\{X_{01},X_{02},...,X_{0p}\\}$ be the set of seeds used to produce the first p components of the sample ,then results are stored in this way:\n$$\n\\begin{align}\nX_{01} \\Rightarrow \\{U_1\\} \\Rightarrow Y_{11}; && X_{01} \\Rightarrow \\{U_1^*\\} \\Rightarrow Y_{21} \\\\\n...\\\\\nX_{0p} \\Rightarrow \\{U_p\\} \\Rightarrow Y_{1p}; && X_{0p} \\Rightarrow \\{U_p^*\\} \\Rightarrow Y_{2p}\n\\end{align}\n$$\nThe observation produced here are then Antithetic and the size of the confidence interval becomes smaller (because of COV is negative) as equal cost. \n","x":-2520,"y":-1600,"width":800,"height":770,"color":"1"},
		{"id":"3c2b426205c090fc","type":"text","text":"## Alternative comparison\nif we must compare 2 systems with different management policies, is possible to reduce the variance. If we want to obtain estimates of a measure computed for the 2 alternatives to decide which is the best we can: simulate the 2 alternatives separately and produce $\\{Y_{11}...Y_{1p}\\},\\{Y_{21}...Y_{2p}\\}$  , then compute $\\bar{Y_1};\\bar{Y_2}$ and then make a decision. \n\nLet $Z_i=(Y_{1i}-Y_{2i})$ , the sample $\\{Z_1...Z_p\\}$ can be used to obtain:\n- Point estimate (sample average) $\\bar{Z} = \\frac{1}{p}\\sum^{p}_{i=1}Z_i=\\bar{Y}_1-\\bar{Y}_2$ \n- Sample variance $\\hat{s}_Z^2=\\frac{1}{p-1}\\sum^{p}_{j=1}(Z_j-\\bar{Z})^2$ \n\nLet $\\micro_1$ and $\\sigma_1^2$ be expected value and variance for $Y_1$ ,same $\\micro_2;\\sigma_2^2$ for $Y_2$ . The comparison would be made on the basis of $E[\\bar{Z}]=E[\\bar{Y}_1]-E[\\bar{Y}_2]=\\micro_1-\\micro_2$ and of $VAR[\\bar{Z}]=VAR[\\bar{Y}_1] + VAR[\\bar{Y}_2] - 2COV[\\bar{Y}_1,\\bar{Y}_2]= \\frac{\\sigma_1^2+\\sigma_2^2}{p} -2 COV[\\bar{Y}_1,\\bar{Y}_2]$ \n\n\nThe individual $Z_i$ and $\\bar{Z}$ as well may assume positive or negative values (and also the extremes of confidence interval). If both are positive or negative the decision is easier. \n\nIf the simulations for the 2 alternatives are performed in an independent manner $COV[\\bar{Y}_1,\\bar{Y}_2]=0$ so that \n$VAR[\\bar{Z}]=VAR[\\bar{Y}_1-\\bar{Y}_2]= \\frac{\\sigma^2_1+\\sigma^2_2}{p}$ also the decision is easy. \n\nif instead the different replications of the 2 experiments are performed with the following scheme:\n$$\n\\begin{align}\nX_{01} \\Rightarrow \\{U_1\\} \\Rightarrow Y_{11}; && X_{01} \\Rightarrow \\{U_1\\} \\Rightarrow Y_{21} \\\\\n...\\\\\nX_{0p} \\Rightarrow \\{U_p\\} \\Rightarrow Y_{1p}; && X_{0p} \\Rightarrow \\{U_p\\} \\Rightarrow Y_{2p}\n\\end{align}\n$$\nwhere X are the seeds. $\\bar{Y}_1$ and $\\bar{Y}_2$ are positively correlated so that $VAR[\\bar{Z}]=VAR[\\bar{Y}_1-\\bar{Y}_2] < \\frac{\\sigma_1^2+\\sigma_2^2}{p}$ \nthen the estimate is more precise with the same computational cost. ","x":-2520,"y":-685,"width":800,"height":770,"color":"1"},
		{"id":"394544e40f451cdf","type":"text","text":"## Result precision \nInterval estimates allow to get confidence in the robustness of the computed results with respect to possible variation, part of the problem however is the precision we want to reach with our estimate. \n\nLet $\\epsilon$ be the required precision and $\\Delta= \\frac{\\hat{s}_Z}{\\bar{v}\\sqrt{p}}$ the semi width of the confidence interval. Knowing that $\\Delta$ depend on the sample size and sample standard deviation we can work on this values to get a better precision, expressed as \n$$\n\\frac{\\Delta}{\\bar{Y}} \\leq \\epsilon\n$$\nIt is better to use a sequential stopping rule to check if the desired precision is reached","x":-2520,"y":240,"width":800,"height":340,"color":"1"},
		{"id":"69cff76702c8670e","type":"text","text":"## Improve results \nThe precision of the simulation rise proportionally to the size of p, an alternative to that is working on the sample variance to make it smaller. 2 interesting cases exists:\n- Antithetic variates to make the sample components pairwise negatively correlated \n- Comparing alternative results by positively correlating the corresponding components of the samples obtained for the two alternatives \n","x":-1400,"y":-620,"width":580,"height":320,"color":"1"},
		{"id":"d1503caf625382fd","type":"text","text":"## Tuning \ntuning consist of: assessing the adequacy of the distributions assumed as part of the specification models, estimating parameters, testing the quality of the variate generators, checking that variations of the parameters produce coherent variations of the results. \n\n","x":-1400,"y":980,"width":580,"height":180,"color":"1"},
		{"id":"05892e06b6433024","type":"text","text":"## Validation\ncheck whether the simulator provides reliable estimates : comparing the simulation output with measures from the real system and with the theoretical values obtained with independent mathematical methods.\n\nIt is also important to use simplified version of the required simulator in order to check it's components. Different version should be considered to make sure that various aspects of the original simulator are checked. \n\nA first way of checking whether the simulator provides reliable estimates is comparing confidence interval (low,up) with a theoretical value $\\micro$ to see if it's covered by the interval. \n\nA more reliable way is implementing the definition of confidence level $1-\\alpha$ which says that:\n_if the experiment is repeated n times, the theoretical value $\\micro$ should be covered by the interval estimates approximate $n(1-\\alpha)$ times, while (approx) for $n \\alpha$ times the confidence interval should not cover the theoretical value._  In practice we may proceed that way:\n- Each experiment consist of repeating the simulation run with different seeds\n- From each experiment compute the point estimate $\\hat{\\micro}$ and the confidence interval $(\\hat{\\micro}-\\Delta,\\hat{\\micro}+\\Delta)$  of the true parameter $\\micro$ \n- Given those hypothesis: (approx) 50% of the experiments should provide a point estimate $\\hat{\\micro}$ that is larger than the theoretical value, while others should be smaller. \n- (approx) $(1-\\alpha )\\%$  of the experiments should provide intervals that include the theoretical value $\\micro$ while $\\alpha\\%$ should not provide intervals which include $\\micro$ ","x":-2540,"y":750,"width":800,"height":640,"color":"1"}
	],
	"edges":[
		{"id":"4de48dfd7459a729","fromNode":"14aeb15597035112","fromSide":"bottom","toNode":"1fb92f5716a05bcc","toSide":"top"},
		{"id":"777a78e500ea045f","fromNode":"14aeb15597035112","fromSide":"right","toNode":"892b702f101ad196","toSide":"left"},
		{"id":"c7b5897d525fcd95","fromNode":"892b702f101ad196","fromSide":"right","toNode":"e7c5ed1f4adca3b7","toSide":"left"},
		{"id":"61cf8ba3a20f08c9","fromNode":"6538a838c6494722","fromSide":"bottom","toNode":"e7c5ed1f4adca3b7","toSide":"top"},
		{"id":"396c0a7ade34703a","fromNode":"e7c5ed1f4adca3b7","fromSide":"bottom","toNode":"1e27b80b5d92dc0f","toSide":"top"},
		{"id":"6bead80d234a61ac","fromNode":"14aeb15597035112","fromSide":"top","toNode":"5f7d906f79d18ccf","toSide":"bottom"},
		{"id":"a1a6c50effac4ab0","fromNode":"5f7d906f79d18ccf","fromSide":"top","toNode":"2f5ba528789510ce","toSide":"bottom"},
		{"id":"34de1d39a5f4c351","fromNode":"2f5ba528789510ce","fromSide":"right","toNode":"27dec0e4325100d4","toSide":"left"},
		{"id":"42d52c3f791c44d9","fromNode":"27dec0e4325100d4","fromSide":"right","toNode":"ed464e34ce17dd95","toSide":"bottom"},
		{"id":"4e3dfc83f5207ff7","fromNode":"ed464e34ce17dd95","fromSide":"top","toNode":"cde292e24b57a8dd","toSide":"bottom"},
		{"id":"4abc7abe66c3824e","fromNode":"ed464e34ce17dd95","fromSide":"top","toNode":"e4d876f751076206","toSide":"bottom"},
		{"id":"cf8f563f711a05b8","fromNode":"ed464e34ce17dd95","fromSide":"top","toNode":"5af1f9b427276358","toSide":"bottom"},
		{"id":"91f2547177537106","fromNode":"27dec0e4325100d4","fromSide":"right","toNode":"705924e1c08aaf8f","toSide":"left"},
		{"id":"ba19a6f497901229","fromNode":"705924e1c08aaf8f","fromSide":"right","toNode":"482c65a1b5cdfd13","toSide":"left"},
		{"id":"67a06b727655bce7","fromNode":"705924e1c08aaf8f","fromSide":"right","toNode":"64466745d12d15df","toSide":"left"},
		{"id":"665cab812eb82ed4","fromNode":"705924e1c08aaf8f","fromSide":"right","toNode":"3ebce3d50050fc9f","toSide":"left"},
		{"id":"b40b56ecaf1d1097","fromNode":"482c65a1b5cdfd13","fromSide":"bottom","toNode":"122347255918062a","toSide":"top"},
		{"id":"9075118358370363","fromNode":"1e27b80b5d92dc0f","fromSide":"right","toNode":"41aa2abc2f91922b","toSide":"left"},
		{"id":"18b72b2f23219dba","fromNode":"1e27b80b5d92dc0f","fromSide":"bottom","toNode":"d227042735bc8cac","toSide":"top"},
		{"id":"80335ce69563b29d","fromNode":"122347255918062a","fromSide":"bottom","toNode":"41aa2abc2f91922b","toSide":"top"},
		{"id":"ebae4dc1f54de4d1","fromNode":"e7c5ed1f4adca3b7","fromSide":"right","toNode":"122347255918062a","toSide":"left"},
		{"id":"b8e9d00ef81ba33c","fromNode":"64466745d12d15df","fromSide":"right","toNode":"955e71b227bca153","toSide":"left"},
		{"id":"ece77fbcb4f4fa12","fromNode":"955e71b227bca153","fromSide":"bottom","toNode":"5020622981f85fb7","toSide":"top"},
		{"id":"f58d4dab90c46db0","fromNode":"122347255918062a","fromSide":"right","toNode":"5020622981f85fb7","toSide":"left"},
		{"id":"a8140548cf3c631f","fromNode":"3ebce3d50050fc9f","fromSide":"right","toNode":"b9fc54566286da56","toSide":"left"},
		{"id":"e2f1f9d98b5ac9f2","fromNode":"b9fc54566286da56","fromSide":"right","toNode":"ba6e055fef30e96a","toSide":"left"},
		{"id":"71d7a59a4e7ab109","fromNode":"ba6e055fef30e96a","fromSide":"right","toNode":"b1fa4f331e5fc959","toSide":"left"},
		{"id":"3128b8e8179f511c","fromNode":"b1fa4f331e5fc959","fromSide":"right","toNode":"7c8e36e60db04d32","toSide":"left"},
		{"id":"d31b6940aeee9625","fromNode":"ba6e055fef30e96a","fromSide":"right","toNode":"701d315c27080880","toSide":"left"},
		{"id":"1bffb4979f2e100c","fromNode":"7c8e36e60db04d32","fromSide":"right","toNode":"52cc6cc700463e75","toSide":"left"},
		{"id":"457a6bc43d7f8c24","fromNode":"701d315c27080880","fromSide":"right","toNode":"cc2f32b57f1d8d8d","toSide":"left"},
		{"id":"05361d89d719cfef","fromNode":"003c1b060de7ec21","fromSide":"top","toNode":"cc2f32b57f1d8d8d","toSide":"bottom"},
		{"id":"127cc0704c1185c9","fromNode":"003c1b060de7ec21","fromSide":"left","toNode":"6802d76c504be239","toSide":"right"},
		{"id":"263b1b3688cb5870","fromNode":"701d315c27080880","fromSide":"right","toNode":"0690d55d9938c6f0","toSide":"left"},
		{"id":"6779db921aa1b1e6","fromNode":"003c1b060de7ec21","fromSide":"left","toNode":"b069e04987fc939c","toSide":"right"},
		{"id":"80adfce3eee58928","fromNode":"cc2f32b57f1d8d8d","fromSide":"right","toNode":"b5c3b5294e37e235","toSide":"left"},
		{"id":"0d3d1870acf0a5b0","fromNode":"cc2f32b57f1d8d8d","fromSide":"right","toNode":"7c8d74969460039c","toSide":"left"},
		{"id":"ea4578e8976e8f6e","fromNode":"cc2f32b57f1d8d8d","fromSide":"right","toNode":"55763f9455c52111","toSide":"left"},
		{"id":"74d56024779ee328","fromNode":"cc2f32b57f1d8d8d","fromSide":"right","toNode":"4205488d88fbe7f4","toSide":"left"},
		{"id":"4275c22d9f62c7ca","fromNode":"cc2f32b57f1d8d8d","fromSide":"top","toNode":"0690d55d9938c6f0","toSide":"bottom"},
		{"id":"d33d0b1acf238eba","fromNode":"0690d55d9938c6f0","fromSide":"right","toNode":"97de64b00abe2f63","toSide":"left"},
		{"id":"384a3c90ba7e034a","fromNode":"97de64b00abe2f63","fromSide":"right","toNode":"2012e7e40eed9f6f","toSide":"left"},
		{"id":"6c21ee1336ee3e0b","fromNode":"97de64b00abe2f63","fromSide":"right","toNode":"02d3c0c6a0517bdc","toSide":"left"},
		{"id":"606cdf2c860a68d6","fromNode":"02d3c0c6a0517bdc","fromSide":"right","toNode":"5df4ad4f48c5f249","toSide":"left"},
		{"id":"ecc7f91d4bcb0b63","fromNode":"5f7d906f79d18ccf","fromSide":"left","toNode":"69cff76702c8670e","toSide":"right"},
		{"id":"1ab1f800c3a80d61","fromNode":"69cff76702c8670e","fromSide":"left","toNode":"924f84dd5d5d2b21","toSide":"right"},
		{"id":"4c4323fe4ba0e0e8","fromNode":"69cff76702c8670e","fromSide":"left","toNode":"3c2b426205c090fc","toSide":"right"},
		{"id":"9556a26b61544f95","fromNode":"69cff76702c8670e","fromSide":"left","toNode":"394544e40f451cdf","toSide":"right"},
		{"id":"ca5940eff63fefef","fromNode":"5f7d906f79d18ccf","fromSide":"left","toNode":"d1503caf625382fd","toSide":"right"},
		{"id":"e9978878c8721284","fromNode":"d1503caf625382fd","fromSide":"left","toNode":"05892e06b6433024","toSide":"right"}
	]
}